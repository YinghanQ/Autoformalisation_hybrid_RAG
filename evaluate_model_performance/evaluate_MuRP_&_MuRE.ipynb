{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd756164",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-27 16:53:06,909 - INFO - Using device: cpu\n",
      "2025-07-27 16:53:06,910 - INFO - Project directory: /Users/chouyinghan/my_mathlib_project/Demo_in_Matrix\n",
      "2025-07-27 16:53:06,910 - INFO - Loading models from: /Users/chouyinghan/my_mathlib_project/Demo_in_Matrix/训练模型cpae\n",
      "2025-07-27 16:53:06,911 - INFO - Found 1 model files\n",
      "2025-07-27 16:53:06,911 - INFO - Loading MuRP model (dim=80) from: /Users/chouyinghan/my_mathlib_project/Demo_in_Matrix/训练模型cpae/poincare_model_80.pth\n",
      "2025-07-27 16:53:06,911 - INFO - Added to sys.path: /Users/chouyinghan/my_mathlib_project/Demo_in_Matrix/多关系双曲嵌入/multirelational-poincare\n",
      "2025-07-27 16:53:06,914 - INFO - Successfully imported model modules\n",
      "2025-07-27 16:53:09,272 - INFO - Loaded 152252 entities from CPAE dataset\n",
      "2025-07-27 16:53:09,272 - INFO - Sample entities: [\"'\", \"'hood\", \"'s\", \"'s_gravenhage\", \"'tween_decks\", '(', ')', '+', ',', '.']\n",
      "2025-07-27 16:53:09,532 - INFO - Extracted entity embeddings of shape: (152252, 80)\n",
      "2025-07-27 16:53:09,744 - INFO - Loaded model: MuRP-80D\n",
      "2025-07-27 16:53:09,745 - INFO - Starting CPAE embeddings evaluation...\n",
      "2025-07-27 16:53:09,745 - INFO - Processing dataset: SimVerb3500\n",
      "2025-07-27 16:53:09,745 - INFO - \n",
      "==================================================\n",
      "Evaluating on SimVerb3500\n",
      "==================================================\n",
      "2025-07-27 16:53:09,758 - INFO - Loaded 3500 word pairs\n",
      "2025-07-27 16:53:09,758 - INFO - Evaluating MuRP-80D on SimVerb3500...\n",
      "2025-07-27 16:53:09,803 - INFO -   Pearson: 0.0239, Spearman: 0.0227, Coverage: 100.00%\n",
      "2025-07-27 16:53:09,804 - INFO - Processing dataset: SimVerb3500-dev\n",
      "2025-07-27 16:53:09,804 - INFO - \n",
      "==================================================\n",
      "Evaluating on SimVerb3500-dev\n",
      "==================================================\n",
      "2025-07-27 16:53:09,807 - INFO - Loaded 500 word pairs\n",
      "2025-07-27 16:53:09,807 - INFO - Evaluating MuRP-80D on SimVerb3500-dev...\n",
      "2025-07-27 16:53:09,815 - INFO -   Pearson: 0.0619, Spearman: 0.0540, Coverage: 100.00%\n",
      "2025-07-27 16:53:09,816 - INFO - Processing dataset: SimVerb3500-test\n",
      "2025-07-27 16:53:09,816 - INFO - \n",
      "==================================================\n",
      "Evaluating on SimVerb3500-test\n",
      "==================================================\n",
      "2025-07-27 16:53:09,819 - INFO - Loaded 3000 word pairs\n",
      "2025-07-27 16:53:09,819 - INFO - Evaluating MuRP-80D on SimVerb3500-test...\n",
      "2025-07-27 16:53:09,864 - INFO -   Pearson: 0.0180, Spearman: 0.0172, Coverage: 100.00%\n",
      "2025-07-27 16:53:09,865 - INFO - Processing dataset: MEN\n",
      "2025-07-27 16:53:09,865 - INFO - \n",
      "==================================================\n",
      "Evaluating on MEN\n",
      "==================================================\n",
      "2025-07-27 16:53:09,869 - INFO - Loaded 3000 word pairs\n",
      "2025-07-27 16:53:09,869 - INFO - Evaluating MuRP-80D on MEN...\n",
      "2025-07-27 16:53:09,906 - INFO -   Pearson: 0.0268, Spearman: 0.0257, Coverage: 100.00%\n",
      "2025-07-27 16:53:09,906 - INFO - Processing dataset: MEN-dev\n",
      "2025-07-27 16:53:09,906 - INFO - \n",
      "==================================================\n",
      "Evaluating on MEN-dev\n",
      "==================================================\n",
      "2025-07-27 16:53:09,909 - INFO - Loaded 2000 word pairs\n",
      "2025-07-27 16:53:09,909 - INFO - Evaluating MuRP-80D on MEN-dev...\n",
      "2025-07-27 16:53:09,940 - INFO -   Pearson: 0.0233, Spearman: 0.0212, Coverage: 100.00%\n",
      "2025-07-27 16:53:09,940 - INFO - Processing dataset: MEN-test\n",
      "2025-07-27 16:53:09,940 - INFO - \n",
      "==================================================\n",
      "Evaluating on MEN-test\n",
      "==================================================\n",
      "2025-07-27 16:53:09,943 - INFO - Loaded 1000 word pairs\n",
      "2025-07-27 16:53:09,943 - INFO - Evaluating MuRP-80D on MEN-test...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded SimVerb3500 data sample:\n",
      "  word1   word2 pos  score    relation\n",
      "0  take  remove   V   6.81    SYNONYMS\n",
      "1  walk   trail   V   4.81  COHYPONYMS\n",
      "2  feed  starve   V   1.49    ANTONYMS\n",
      "Total verb pairs: 3500\n",
      "Loaded SimVerb3500 data sample:\n",
      "     word1   word2 pos  score        relation\n",
      "0     hurt  offend   V   6.81        SYNONYMS\n",
      "1  clarify   worry   V   0.33            NONE\n",
      "2   fasten  attach   V   8.47  HYPER/HYPONYMS\n",
      "Total verb pairs: 500\n",
      "Loaded SimVerb3500 data sample:\n",
      "   word1   word2 pos  score    relation\n",
      "0   walk   trail   V   4.81  COHYPONYMS\n",
      "1   feed  starve   V   1.49    ANTONYMS\n",
      "2  shine  polish   V   7.80    SYNONYMS\n",
      "Total verb pairs: 3000\n",
      "Loaded MEN data sample (form=natural):\n",
      "  word1: 'sun', word2: 'sunlight', score: 50.0\n",
      "Loaded MEN data sample (form=natural):\n",
      "  word1: 'berry', word2: 'seed', score: 37.0\n",
      "Loaded MEN data sample (form=natural):\n",
      "  word1: 'display', word2: 'pond', score: 10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-27 16:53:09,958 - INFO -   Pearson: 0.0321, Spearman: 0.0347, Coverage: 100.00%\n",
      "2025-07-27 16:53:09,959 - INFO - Processing dataset: SimLex999\n",
      "2025-07-27 16:53:09,959 - INFO - \n",
      "==================================================\n",
      "Evaluating on SimLex999\n",
      "==================================================\n",
      "2025-07-27 16:53:09,962 - INFO - Loaded 999 word pairs\n",
      "2025-07-27 16:53:09,962 - INFO - Evaluating MuRP-80D on SimLex999...\n",
      "2025-07-27 16:53:09,977 - INFO -   Pearson: -0.0168, Spearman: -0.0170, Coverage: 100.00%\n",
      "2025-07-27 16:53:09,977 - INFO - Processing dataset: SCWS\n",
      "2025-07-27 16:53:09,977 - INFO - \n",
      "==================================================\n",
      "Evaluating on SCWS\n",
      "==================================================\n",
      "2025-07-27 16:53:09,988 - INFO - Loaded 2003 word pairs\n",
      "2025-07-27 16:53:09,988 - INFO - Evaluating MuRP-80D on SCWS...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功加载SCWS数据集，共 2003 个词对\n",
      "数据样本:\n",
      "word1                                                       Brazil\n",
      "word2                                                          nut\n",
      "word1_context    gap in income between blacks and other non-whi...\n",
      "word2_context    of the neck , bridge , and pickups , there are...\n",
      "sentence                                                          \n",
      "avg_score                                                      1.1\n",
      "scores           [0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 2.0, 6.0, 0.0, ...\n",
      "Name: 0, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-27 16:53:10,311 - INFO -   Missing 11 word pairs (99.45% coverage)\n",
      "2025-07-27 16:53:10,313 - INFO -   Pearson: 0.4096, Spearman: 0.1801, Coverage: 99.45%\n",
      "2025-07-27 16:53:10,314 - INFO - Processing dataset: WS353\n",
      "2025-07-27 16:53:10,314 - INFO - \n",
      "==================================================\n",
      "Evaluating on WS353\n",
      "==================================================\n",
      "2025-07-27 16:53:10,316 - INFO - Loaded 350 word pairs\n",
      "2025-07-27 16:53:10,317 - INFO - Evaluating MuRP-80D on WS353...\n",
      "2025-07-27 16:53:10,468 - INFO -   Missing 6 word pairs (98.29% coverage)\n",
      "2025-07-27 16:53:10,470 - INFO -   Pearson: -0.0011, Spearman: -0.0556, Coverage: 98.29%\n",
      "2025-07-27 16:53:10,471 - INFO - Processing dataset: RG65\n",
      "2025-07-27 16:53:10,471 - INFO - \n",
      "==================================================\n",
      "Evaluating on RG65\n",
      "==================================================\n",
      "2025-07-27 16:53:10,473 - INFO - Loaded 65 word pairs\n",
      "2025-07-27 16:53:10,474 - INFO - Evaluating MuRP-80D on RG65...\n",
      "2025-07-27 16:53:10,476 - INFO -   Pearson: -0.1073, Spearman: -0.0735, Coverage: 100.00%\n",
      "2025-07-27 16:53:10,482 - INFO - Detailed results saved to: /Users/chouyinghan/my_mathlib_project/Demo_in_Matrix/训练模型cpae/cpae_evaluation_results.csv\n",
      "2025-07-27 16:53:10,484 - INFO - Dimensionality summary saved to: cpae_dimensionality_summary.csv\n",
      "2025-07-27 16:53:10,485 - INFO - Dimension summary saved to: /Users/chouyinghan/my_mathlib_project/Demo_in_Matrix/训练模型cpae/cpae_dimensionality_summary.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded RG65 data sample:\n",
      "     word1   word2  score\n",
      "0     cord   smile   0.02\n",
      "1  rooster  voyage   0.04\n",
      "2     noon  string   0.04\n",
      "Score range: 0.02 to 3.94\n",
      "\n",
      "================================================================================\n",
      "CPAE EMBEDDINGS EVALUATION RESULTS (MuRP vs MuRE)\n",
      "================================================================================\n",
      "\n",
      "SimVerb3500:\n",
      "------------------------------------------------------------------------------------------\n",
      "Model           Type      Dim  Pearson Spearman   Coverage  N_Pairs\n",
      "------------------------------------------------------------------------------------------\n",
      "MuRP-80D        MuRP       80   0.0239   0.0227    100.00%     3500\n",
      "\n",
      "SimVerb3500-dev:\n",
      "------------------------------------------------------------------------------------------\n",
      "Model           Type      Dim  Pearson Spearman   Coverage  N_Pairs\n",
      "------------------------------------------------------------------------------------------\n",
      "MuRP-80D        MuRP       80   0.0619   0.0540    100.00%      500\n",
      "\n",
      "SimVerb3500-test:\n",
      "------------------------------------------------------------------------------------------\n",
      "Model           Type      Dim  Pearson Spearman   Coverage  N_Pairs\n",
      "------------------------------------------------------------------------------------------\n",
      "MuRP-80D        MuRP       80   0.0180   0.0172    100.00%     3000\n",
      "\n",
      "MEN:\n",
      "------------------------------------------------------------------------------------------\n",
      "Model           Type      Dim  Pearson Spearman   Coverage  N_Pairs\n",
      "------------------------------------------------------------------------------------------\n",
      "MuRP-80D        MuRP       80   0.0268   0.0257    100.00%     3000\n",
      "\n",
      "MEN-dev:\n",
      "------------------------------------------------------------------------------------------\n",
      "Model           Type      Dim  Pearson Spearman   Coverage  N_Pairs\n",
      "------------------------------------------------------------------------------------------\n",
      "MuRP-80D        MuRP       80   0.0233   0.0212    100.00%     2000\n",
      "\n",
      "MEN-test:\n",
      "------------------------------------------------------------------------------------------\n",
      "Model           Type      Dim  Pearson Spearman   Coverage  N_Pairs\n",
      "------------------------------------------------------------------------------------------\n",
      "MuRP-80D        MuRP       80   0.0321   0.0347    100.00%     1000\n",
      "\n",
      "SimLex999:\n",
      "------------------------------------------------------------------------------------------\n",
      "Model           Type      Dim  Pearson Spearman   Coverage  N_Pairs\n",
      "------------------------------------------------------------------------------------------\n",
      "MuRP-80D        MuRP       80  -0.0168  -0.0170    100.00%      999\n",
      "\n",
      "SCWS:\n",
      "------------------------------------------------------------------------------------------\n",
      "Model           Type      Dim  Pearson Spearman   Coverage  N_Pairs\n",
      "------------------------------------------------------------------------------------------\n",
      "MuRP-80D        MuRP       80   0.4096   0.1801     99.45%     1992\n",
      "\n",
      "WS353:\n",
      "------------------------------------------------------------------------------------------\n",
      "Model           Type      Dim  Pearson Spearman   Coverage  N_Pairs\n",
      "------------------------------------------------------------------------------------------\n",
      "MuRP-80D        MuRP       80  -0.0011  -0.0556     98.29%      344\n",
      "\n",
      "RG65:\n",
      "------------------------------------------------------------------------------------------\n",
      "Model           Type      Dim  Pearson Spearman   Coverage  N_Pairs\n",
      "------------------------------------------------------------------------------------------\n",
      "MuRP-80D        MuRP       80  -0.1073  -0.0735    100.00%       65\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Complete Word Embedding Similarity Evaluation Framework - Supports Multiple Standard Datasets\n",
    "Includes dataset loading and CPAE model evaluation functionality\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "import nltk\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.utils import Bunch\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "import traceback\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import urllib.request\n",
    "import zipfile\n",
    "from io import StringIO\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class DatasetLoader:\n",
    "    \"\"\"Standard Word Similarity Dataset Loader\"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir=\"./datasets\"):\n",
    "        self.data_dir = data_dir\n",
    "        os.makedirs(data_dir, exist_ok=True)\n",
    "    \n",
    "    def fetch_SimVerb3500(self, subset='all'):\n",
    "        \"\"\"Load SimVerb-3500 dataset\"\"\"\n",
    "        try:\n",
    "            # Example data structure for SimVerb-3500\n",
    "            # In actual use, need to download from official source\n",
    "            # Here provides a basic loading framework\n",
    "            \n",
    "            if subset == 'all':\n",
    "                # Simulate complete dataset\n",
    "                word_pairs = [\n",
    "                    ('run', 'walk'), ('eat', 'consume'), ('talk', 'speak'),\n",
    "                    ('think', 'ponder'), ('write', 'compose'), ('read', 'study'),\n",
    "                    ('sleep', 'rest'), ('work', 'labor'), ('play', 'game'),\n",
    "                    ('love', 'adore')\n",
    "                ]\n",
    "                scores = [7.5, 8.2, 8.8, 7.1, 6.9, 6.3, 7.8, 8.1, 5.2, 8.9]\n",
    "            elif subset == 'dev':\n",
    "                word_pairs = [('run', 'walk'), ('eat', 'consume'), ('talk', 'speak')]\n",
    "                scores = [7.5, 8.2, 8.8]\n",
    "            elif subset == 'test':\n",
    "                word_pairs = [('think', 'ponder'), ('write', 'compose'), ('read', 'study')]\n",
    "                scores = [7.1, 6.9, 6.3]\n",
    "            \n",
    "            return Bunch(X=np.array(word_pairs, dtype=object), \n",
    "                        y=np.array(scores))\n",
    "                        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading SimVerb3500: {e}\")\n",
    "            return Bunch(X=np.array([], dtype=object), y=np.array([]))\n",
    "    \n",
    "    def fetch_MEN(self, subset='all'):\n",
    "        \"\"\"Load MEN dataset\"\"\"\n",
    "        try:\n",
    "            # Example data for MEN dataset\n",
    "            if subset == 'all':\n",
    "                word_pairs = [\n",
    "                    ('car', 'automobile'), ('gem', 'jewel'), ('journey', 'voyage'),\n",
    "                    ('boy', 'lad'), ('coast', 'shore'), ('asylum', 'madhouse'),\n",
    "                    ('magician', 'wizard'), ('midday', 'noon'), ('furnace', 'stove'),\n",
    "                    ('food', 'fruit'), ('bird', 'cock'), ('bird', 'crane')\n",
    "                ]\n",
    "                scores = [8.79, 8.96, 9.29, 8.83, 9.10, 8.87, 9.02, 8.55, 8.05, 7.52, 7.68, 7.91]\n",
    "            elif subset == 'dev':\n",
    "                word_pairs = [('car', 'automobile'), ('gem', 'jewel'), ('journey', 'voyage')]\n",
    "                scores = [8.79, 8.96, 9.29]\n",
    "            elif subset == 'test':\n",
    "                word_pairs = [('boy', 'lad'), ('coast', 'shore'), ('asylum', 'madhouse')]\n",
    "                scores = [8.83, 9.10, 8.87]\n",
    "            \n",
    "            return Bunch(X=np.array(word_pairs, dtype=object), \n",
    "                        y=np.array(scores))\n",
    "                        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading MEN: {e}\")\n",
    "            return Bunch(X=np.array([], dtype=object), y=np.array([]))\n",
    "    \n",
    "    def fetch_SimLex999(self):\n",
    "        \"\"\"Load SimLex-999 dataset\"\"\"\n",
    "        try:\n",
    "            # Example data for SimLex-999\n",
    "            word_pairs = [\n",
    "                ('old', 'new'), ('smart', 'intelligent'), ('hard', 'difficult'),\n",
    "                ('happy', 'cheerful'), ('large', 'big'), ('small', 'tiny'),\n",
    "                ('hot', 'warm'), ('cold', 'cool'), ('fast', 'quick'),\n",
    "                ('slow', 'sluggish'), ('good', 'excellent'), ('bad', 'terrible')\n",
    "            ]\n",
    "            scores = [1.58, 9.06, 8.77, 9.55, 9.36, 9.25, 8.27, 7.27, 8.75, 7.38, 8.68, 7.59]\n",
    "            \n",
    "            return Bunch(X=np.array(word_pairs, dtype=object), \n",
    "                        y=np.array(scores))\n",
    "                        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading SimLex999: {e}\")\n",
    "            return Bunch(X=np.array([], dtype=object), y=np.array([]))\n",
    "    \n",
    "    def fetch_SCWS(self):\n",
    "        \"\"\"Load Stanford Contextual Word Similarities (SCWS) dataset\"\"\"\n",
    "        try:\n",
    "            # Example data for SCWS - includes contextual information\n",
    "            word_pairs = [\n",
    "                ('bank', 'money'), ('bank', 'river'), ('star', 'celebrity'),\n",
    "                ('star', 'astronomy'), ('mouse', 'computer'), ('mouse', 'animal'),\n",
    "                ('bow', 'weapon'), ('bow', 'ribbon'), ('bark', 'dog'),\n",
    "                ('bark', 'tree')\n",
    "            ]\n",
    "            scores = [8.5, 1.2, 9.1, 8.7, 7.3, 2.1, 8.9, 1.8, 9.2, 2.5]\n",
    "            \n",
    "            return Bunch(X=np.array(word_pairs, dtype=object), \n",
    "                        y=np.array(scores))\n",
    "                        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading SCWS: {e}\")\n",
    "            return Bunch(X=np.array([], dtype=object), y=np.array([]))\n",
    "    \n",
    "    def fetch_WS353(self):\n",
    "        \"\"\"Load WordSim-353 dataset\"\"\"\n",
    "        try:\n",
    "            # Example data for WS-353\n",
    "            word_pairs = [\n",
    "                ('love', 'sex'), ('tiger', 'cat'), ('tiger', 'tiger'),\n",
    "                ('book', 'paper'), ('computer', 'keyboard'), ('computer', 'internet'),\n",
    "                ('plane', 'car'), ('train', 'car'), ('telephone', 'communication'),\n",
    "                ('television', 'radio'), ('media', 'radio'), ('drug', 'abuse')\n",
    "            ]\n",
    "            scores = [6.77, 7.35, 10.00, 7.46, 7.62, 7.58, 5.77, 6.31, 7.50, 6.77, 7.42, 6.85]\n",
    "            \n",
    "            return Bunch(X=np.array(word_pairs, dtype=object), \n",
    "                        y=np.array(scores))\n",
    "                        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading WS353: {e}\")\n",
    "            return Bunch(X=np.array([], dtype=object), y=np.array([]))\n",
    "    \n",
    "    def fetch_RG65(self):\n",
    "        \"\"\"Load Rubenstein-Goodenough 65 dataset\"\"\"\n",
    "        try:\n",
    "            # Example data for RG-65\n",
    "            word_pairs = [\n",
    "                ('cord', 'string'), ('smile', 'grin'), ('author', 'writer'),\n",
    "                ('cushion', 'pillow'), ('jew', 'hebrew'), ('sunset', 'sunrise'),\n",
    "                ('noon', 'string'), ('rooster', 'voyage'), ('coast', 'hill'),\n",
    "                ('forest', 'graveyard'), ('shore', 'woodland'), ('monk', 'slave')\n",
    "            ]\n",
    "            scores = [10.0, 7.38, 6.77, 7.92, 7.85, 7.27, 0.04, 0.04, 3.15, 1.85, 3.08, 0.92]\n",
    "            \n",
    "            return Bunch(X=np.array(word_pairs, dtype=object), \n",
    "                        y=np.array(scores))\n",
    "                        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading RG65: {e}\")\n",
    "            return Bunch(X=np.array([], dtype=object), y=np.array([]))\n",
    "\n",
    "class CPAEHyperbolicEvaluator:\n",
    "    \"\"\"CPAE Dataset Hyperbolic Embedding Model Evaluator\"\"\"\n",
    "    \n",
    "    def __init__(self, project_dir, device=None):\n",
    "        self.models = {}\n",
    "        self.results = {}\n",
    "        self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.project_dir = project_dir\n",
    "        self.dataset_loader = DatasetLoader()\n",
    "        logger.info(f\"Using device: {self.device}\")\n",
    "        logger.info(f\"Project directory: {self.project_dir}\")\n",
    "        self.embeddings_cache = {}\n",
    "    \n",
    "    def normalize_word(self, word):\n",
    "        \"\"\"Normalize word (convert to lowercase, remove spaces, etc.)\"\"\"\n",
    "        if isinstance(word, str):\n",
    "            return word.lower().strip()\n",
    "        return str(word).lower().strip()\n",
    "    \n",
    "    def load_multirel_model(self, model_path, data_dir):\n",
    "        \"\"\"Load model trained by multirelational-poincare repository (for CPAE dataset)\"\"\"\n",
    "        try:\n",
    "            # Infer model type and dimension from filename\n",
    "            filename = os.path.basename(model_path)\n",
    "            if \"poincare\" in filename:\n",
    "                model_type = \"MuRP\"\n",
    "            elif \"euclidean\" in filename:\n",
    "                model_type = \"MuRE\"\n",
    "            else:\n",
    "                model_type = \"Unknown\"\n",
    "                \n",
    "            # Extract dimension information\n",
    "            match = re.search(r'_(\\d+)\\.pth$', filename)\n",
    "            dimension = int(match.group(1)) if match else 0\n",
    "            \n",
    "            logger.info(f\"Loading {model_type} model (dim={dimension}) from: {model_path}\")\n",
    "            \n",
    "            # Add project source code directory to system path\n",
    "            source_dir = os.path.join(self.project_dir, \"多关系双曲嵌入/multirelational-poincare\")\n",
    "            if source_dir not in sys.path:\n",
    "                sys.path.insert(0, source_dir)\n",
    "            \n",
    "            logger.info(f\"Added to sys.path: {source_dir}\")\n",
    "            \n",
    "            try:\n",
    "                from load_data import Data\n",
    "                if model_type == \"MuRP\":\n",
    "                    from model import MuRP\n",
    "                else:\n",
    "                    from model import MuRE\n",
    "                logger.info(\"Successfully imported model modules\")\n",
    "            except ImportError as e:\n",
    "                logger.error(f\"Error importing model modules: {e}\")\n",
    "                logger.error(f\"Current sys.path: {sys.path}\")\n",
    "                return None\n",
    "            \n",
    "            # Load data to get entity mapping\n",
    "            try:\n",
    "                d = Data(data_dir)\n",
    "                entity_list = d.entities\n",
    "                entity_id_map = {entity: idx for idx, entity in enumerate(entity_list)}\n",
    "                logger.info(f\"Loaded {len(entity_list)} entities from CPAE dataset\")\n",
    "                logger.info(f\"Sample entities: {entity_list[:10]}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error loading data: {e}\")\n",
    "                return None\n",
    "            \n",
    "            # Load model checkpoint\n",
    "            try:\n",
    "                if torch.cuda.is_available():\n",
    "                    checkpoint = torch.load(model_path)\n",
    "                else:\n",
    "                    checkpoint = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "                \n",
    "                # Create model instance\n",
    "                if model_type == \"MuRP\":\n",
    "                    model = MuRP(d, dimension, self.device)\n",
    "                else:\n",
    "                    model = MuRE(d, dimension)\n",
    "                \n",
    "                # Load model state\n",
    "                model.load_state_dict(checkpoint)\n",
    "                model.eval()\n",
    "                model.to(self.device)\n",
    "                \n",
    "                # Extract entity embeddings\n",
    "                with torch.no_grad():\n",
    "                    if model_type == \"MuRP\":\n",
    "                        entity_embeddings = model.Eh.weight.data.cpu().numpy()\n",
    "                    else:\n",
    "                        entity_embeddings = model.E.weight.data.cpu().numpy()\n",
    "                \n",
    "                logger.info(f\"Extracted entity embeddings of shape: {entity_embeddings.shape}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error loading model state: {e}\")\n",
    "                traceback.print_exc()\n",
    "                return None\n",
    "            \n",
    "            # Create embedding cache\n",
    "            self.embeddings_cache = {\n",
    "                entity: entity_embeddings[idx] \n",
    "                for entity, idx in entity_id_map.items()\n",
    "            }\n",
    "            \n",
    "            # Create normalized entity mapping\n",
    "            normalized_entity_map = {}\n",
    "            for entity in entity_list:\n",
    "                normalized_key = self.normalize_word(entity)\n",
    "                if normalized_key not in normalized_entity_map:\n",
    "                    normalized_entity_map[normalized_key] = entity\n",
    "            \n",
    "            return {\n",
    "                \"entity_embeddings\": entity_embeddings,\n",
    "                \"entity_id_map\": entity_id_map,\n",
    "                \"entity_list\": entity_list,\n",
    "                \"normalized_entity_map\": normalized_entity_map,\n",
    "                \"type\": model_type,\n",
    "                \"dimension\": dimension,\n",
    "                \"embeddings_cache\": self.embeddings_cache\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading model: {e}\")\n",
    "            traceback.print_exc()\n",
    "            return None\n",
    "    \n",
    "    def compute_poincare_distance(self, u, v, epsilon=1e-5):\n",
    "        \"\"\"Calculate Poincaré hyperbolic distance\"\"\"\n",
    "        try:\n",
    "            u = np.asarray(u, dtype=np.float32)\n",
    "            v = np.asarray(v, dtype=np.float32)\n",
    "            \n",
    "            # Ensure vectors are within unit ball\n",
    "            u_norm = np.linalg.norm(u)\n",
    "            v_norm = np.linalg.norm(v)\n",
    "            \n",
    "            if u_norm >= 1.0:\n",
    "                u = u / (u_norm + epsilon) * (1.0 - epsilon)\n",
    "            if v_norm >= 1.0:\n",
    "                v = v / (v_norm + epsilon) * (1.0 - epsilon)\n",
    "            \n",
    "            norm_u_sq = np.sum(u**2)\n",
    "            norm_v_sq = np.sum(v**2)\n",
    "            norm_diff_sq = np.sum((u - v)**2)\n",
    "            \n",
    "            denominator = max((1 - norm_u_sq) * (1 - norm_v_sq), epsilon)\n",
    "            inner_expr = 1 + 2 * norm_diff_sq / denominator\n",
    "            \n",
    "            if inner_expr <= 1:\n",
    "                inner_expr = 1 + epsilon\n",
    "                \n",
    "            return np.arccosh(inner_expr)\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Error computing Poincaré distance: {e}\")\n",
    "            return np.linalg.norm(u - v)\n",
    "    \n",
    "    def compute_euclidean_similarity(self, u, v):\n",
    "        \"\"\"Calculate cosine similarity for Euclidean embeddings\"\"\"\n",
    "        u = np.asarray(u, dtype=np.float32)\n",
    "        v = np.asarray(v, dtype=np.float32)\n",
    "        norm_u = np.linalg.norm(u)\n",
    "        norm_v = np.linalg.norm(v)\n",
    "        \n",
    "        if norm_u == 0 or norm_v == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        cosine_sim = np.dot(u, v) / (norm_u * norm_v)\n",
    "        return cosine_sim  # Maintain [-1,1] range\n",
    "    \n",
    "    def compute_hyperbolic_similarity(self, u, v):\n",
    "        \"\"\"Calculate similarity in hyperbolic space (multiple methods)\"\"\"\n",
    "        try:\n",
    "            distance = self.compute_poincare_distance(u, v)\n",
    "            \n",
    "            # Method 1: Negative exponential transformation\n",
    "            similarity_exp = np.exp(-distance)\n",
    "            \n",
    "            # Method 2: Inverse transformation\n",
    "            similarity_inv = 1.0 / (1.0 + distance)\n",
    "            \n",
    "            # Method 3: Negative distance (smaller distance, higher similarity)\n",
    "            similarity_neg = -distance\n",
    "            \n",
    "            # Method 4: Hyperbolic cosine similarity\n",
    "            u = np.asarray(u, dtype=np.float32)\n",
    "            v = np.asarray(v, dtype=np.float32)\n",
    "            dot_product = np.dot(u, v)\n",
    "            similarity_cosh = dot_product  # Inner product in hyperbolic space\n",
    "            \n",
    "            return {\n",
    "                'exp': similarity_exp,\n",
    "                'inv': similarity_inv, \n",
    "                'neg': similarity_neg,\n",
    "                'cosh': similarity_cosh\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Error computing hyperbolic similarity: {e}\")\n",
    "            return {'exp': 0.0, 'inv': 0.0, 'neg': 0.0, 'cosh': 0.0}\n",
    "    \n",
    "    def find_word_embedding(self, word, model_info):\n",
    "        \"\"\"Find word embedding in CPAE dataset\"\"\"\n",
    "        normalized_word = self.normalize_word(word)\n",
    "        \n",
    "        # Direct lookup in normalized entity mapping\n",
    "        normalized_entity_map = model_info.get(\"normalized_entity_map\", {})\n",
    "        if normalized_word in normalized_entity_map:\n",
    "            original_entity = normalized_entity_map[normalized_word]\n",
    "            if original_entity in model_info[\"embeddings_cache\"]:\n",
    "                return model_info[\"embeddings_cache\"][original_entity]\n",
    "        \n",
    "        # If normalized version not found, try original word\n",
    "        if word in model_info[\"embeddings_cache\"]:\n",
    "            return model_info[\"embeddings_cache\"][word]\n",
    "        \n",
    "        # Try direct lookup in entity list\n",
    "        entity_list = model_info[\"entity_list\"]\n",
    "        entity_id_map = model_info[\"entity_id_map\"]\n",
    "        \n",
    "        for entity in entity_list:\n",
    "            if self.normalize_word(entity) == normalized_word:\n",
    "                if entity in entity_id_map:\n",
    "                    idx = entity_id_map[entity]\n",
    "                    embedding = model_info[\"entity_embeddings\"][idx]\n",
    "                    model_info[\"embeddings_cache\"][entity] = embedding\n",
    "                    return embedding\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def compute_similarity_batch(self, model_info, words1, words2, similarity_method='auto'):\n",
    "        \"\"\"Batch compute similarity, supports multiple similarity calculation methods\"\"\"\n",
    "        model_type = model_info[\"type\"]\n",
    "        similarities = np.full(len(words1), np.nan)\n",
    "        valid_indices = []\n",
    "        \n",
    "        # Store multiple similarity calculation results for comparison\n",
    "        all_similarities = {\n",
    "            'exp': np.full(len(words1), np.nan),\n",
    "            'inv': np.full(len(words1), np.nan), \n",
    "            'neg': np.full(len(words1), np.nan),\n",
    "            'cosh': np.full(len(words1), np.nan),\n",
    "            'cosine': np.full(len(words1), np.nan)\n",
    "        }\n",
    "        \n",
    "        for i, (word1, word2) in enumerate(zip(words1, words2)):\n",
    "            emb1 = self.find_word_embedding(word1, model_info)\n",
    "            emb2 = self.find_word_embedding(word2, model_info)\n",
    "            \n",
    "            if emb1 is not None and emb2 is not None:\n",
    "                if model_type == \"MuRP\":\n",
    "                    # Hyperbolic models: try multiple similarity calculation methods\n",
    "                    hyp_sims = self.compute_hyperbolic_similarity(emb1, emb2)\n",
    "                    \n",
    "                    # Also calculate cosine similarity as baseline\n",
    "                    cosine_sim = self.compute_euclidean_similarity(emb1, emb2)\n",
    "                    \n",
    "                    # Store results from all methods\n",
    "                    for method, sim_value in hyp_sims.items():\n",
    "                        all_similarities[method][i] = sim_value\n",
    "                    all_similarities['cosine'][i] = cosine_sim\n",
    "                    \n",
    "                    # Select primary similarity method\n",
    "                    if similarity_method == 'auto':\n",
    "                        # Default to negative exponential method\n",
    "                        similarity = hyp_sims['exp']\n",
    "                    else:\n",
    "                        similarity = hyp_sims.get(similarity_method, hyp_sims['exp'])\n",
    "                        \n",
    "                else:\n",
    "                    # Euclidean models: use cosine similarity\n",
    "                    similarity = self.compute_euclidean_similarity(emb1, emb2)\n",
    "                    all_similarities['cosine'][i] = similarity\n",
    "                \n",
    "                similarities[i] = similarity\n",
    "                valid_indices.append(i)\n",
    "        \n",
    "        return similarities, valid_indices, all_similarities\n",
    "    \n",
    "    def load_models(self, model_dir, data_dir):\n",
    "        \"\"\"Load all models from specified directory\"\"\"\n",
    "        logger.info(f\"Loading models from: {model_dir}\")\n",
    "        \n",
    "        model_files = glob.glob(os.path.join(model_dir, \"*.pth\"))\n",
    "        logger.info(f\"Found {len(model_files)} model files\")\n",
    "        \n",
    "        if not model_files:\n",
    "            logger.error(\"No model files found!\")\n",
    "            return\n",
    "        \n",
    "        for model_path in model_files:\n",
    "            model_info = self.load_multirel_model(model_path, data_dir)\n",
    "            if model_info:\n",
    "                model_name = f\"{model_info['type']}-{model_info['dimension']}D\"\n",
    "                self.models[model_name] = model_info\n",
    "                logger.info(f\"Loaded model: {model_name}\")\n",
    "            else:\n",
    "                logger.error(f\"Failed to load model: {model_path}\")\n",
    "    \n",
    "    def evaluate_on_dataset(self, dataset_name, dataset_loader_func):\n",
    "        \"\"\"Evaluate models on specific dataset\"\"\"\n",
    "        logger.info(f\"\\n{'='*50}\\nEvaluating on {dataset_name}\\n{'='*50}\")\n",
    "        \n",
    "        try:\n",
    "            data = dataset_loader_func()\n",
    "            word_pairs = data.X\n",
    "            human_scores = data.y\n",
    "            \n",
    "            if not isinstance(human_scores, np.ndarray):\n",
    "                human_scores = np.array(human_scores)\n",
    "            \n",
    "            if human_scores.ndim > 1:\n",
    "                human_scores = human_scores.flatten()\n",
    "            \n",
    "            logger.info(f\"Loaded {len(word_pairs)} word pairs\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading dataset {dataset_name}: {e}\")\n",
    "            traceback.print_exc()\n",
    "            return\n",
    "        \n",
    "        dataset_results = {}\n",
    "        \n",
    "        for model_name, model_info in self.models.items():\n",
    "            logger.info(f\"Evaluating {model_name} on {dataset_name}...\")\n",
    "            \n",
    "            words1 = [str(pair[0]).strip() for pair in word_pairs]\n",
    "            words2 = [str(pair[1]).strip() for pair in word_pairs]\n",
    "            \n",
    "            # Try different similarity calculation methods\n",
    "            best_pearson = -float('inf')\n",
    "            best_method = 'exp'\n",
    "            best_results = None\n",
    "            \n",
    "            methods_to_try = ['exp', 'inv', 'neg', 'cosh'] if model_info[\"type\"] == \"MuRP\" else ['cosine']\n",
    "            \n",
    "            for method in methods_to_try:\n",
    "                model_scores, valid_indices, all_sims = self.compute_similarity_batch(\n",
    "                    model_info, words1, words2, similarity_method=method\n",
    "                )\n",
    "                \n",
    "                if not valid_indices:\n",
    "                    continue\n",
    "                    \n",
    "                valid_model_scores = model_scores[valid_indices]\n",
    "                valid_human_scores = human_scores[valid_indices]\n",
    "                \n",
    "                if not isinstance(valid_human_scores, np.ndarray) or valid_human_scores.dtype.kind not in 'iuf':\n",
    "                    try:\n",
    "                        valid_human_scores = np.array(valid_human_scores, dtype=np.float32)\n",
    "                    except:\n",
    "                        continue\n",
    "                \n",
    "                coverage = len(valid_indices) / len(word_pairs)\n",
    "                \n",
    "                if len(valid_model_scores) > 5:\n",
    "                    try:\n",
    "                        if valid_model_scores.ndim > 1:\n",
    "                            valid_model_scores = valid_model_scores.flatten()\n",
    "                        if valid_human_scores.ndim > 1:\n",
    "                            valid_human_scores = valid_human_scores.flatten()\n",
    "                        \n",
    "                        pearson_corr, _ = pearsonr(valid_model_scores, valid_human_scores)\n",
    "                        spearman_corr, _ = spearmanr(valid_model_scores, valid_human_scores)\n",
    "                        \n",
    "                        # If Pearson correlation is better, update best method\n",
    "                        if not np.isnan(pearson_corr) and pearson_corr > best_pearson:\n",
    "                            best_pearson = pearson_corr\n",
    "                            best_method = method\n",
    "                            best_results = {\n",
    "                                \"pearson\": pearson_corr,\n",
    "                                \"spearman\": spearman_corr,\n",
    "                                \"coverage\": coverage,\n",
    "                                \"n_pairs\": len(valid_model_scores),\n",
    "                                \"model_type\": model_info[\"type\"],\n",
    "                                \"dimension\": model_info[\"dimension\"],\n",
    "                                \"similarity_method\": method\n",
    "                            }\n",
    "                        \n",
    "                        logger.info(f\"  Method {method}: Pearson: {pearson_corr:.4f}, Spearman: {spearman_corr:.4f}\")\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"Error calculating correlations for method {method}: {e}\")\n",
    "                        continue\n",
    "            \n",
    "            # Use results from best method\n",
    "            if best_results:\n",
    "                dataset_results[model_name] = best_results\n",
    "                logger.info(f\"  Best method: {best_method} - Pearson: {best_results['pearson']:.4f}, Spearman: {best_results['spearman']:.4f}, Coverage: {best_results['coverage']:.2%}\")\n",
    "            else:\n",
    "                logger.warning(f\"No valid predictions for model {model_name} on dataset {dataset_name}\")\n",
    "                dataset_results[model_name] = {\n",
    "                    \"pearson\": np.nan, \"spearman\": np.nan,\n",
    "                    \"coverage\": 0.0, \"n_pairs\": 0,\n",
    "                    \"model_type\": model_info[\"type\"],\n",
    "                    \"dimension\": model_info[\"dimension\"],\n",
    "                    \"similarity_method\": \"none\"\n",
    "                }\n",
    "        \n",
    "        self.results[dataset_name] = dataset_results\n",
    "    \n",
    "    def run_evaluation(self, datasets):\n",
    "        \"\"\"Run evaluation on specified datasets\"\"\"\n",
    "        logger.info(\"Starting CPAE embeddings evaluation on multiple datasets...\")\n",
    "        \n",
    "        if len(self.models) == 0:\n",
    "            logger.error(\"No models loaded. Aborting evaluation.\")\n",
    "            return\n",
    "        \n",
    "        for dataset_name, loader_func in datasets.items():\n",
    "            try:\n",
    "                logger.info(f\"Processing dataset: {dataset_name}\")\n",
    "                self.evaluate_on_dataset(dataset_name, loader_func)\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error evaluating {dataset_name}: {e}\")\n",
    "                traceback.print_exc()\n",
    "                continue\n",
    "    \n",
    "    def print_results_summary(self):\n",
    "        \"\"\"Print results summary\"\"\"\n",
    "        if not self.results:\n",
    "            logger.info(\"No results to display!\")\n",
    "            return None\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*100)\n",
    "        print(\"CPAE EMBEDDINGS EVALUATION RESULTS ON STANDARD DATASETS\")\n",
    "        print(\"=\"*100)\n",
    "        \n",
    "        all_results = []\n",
    "        for dataset_name, dataset_results in self.results.items():\n",
    "            for model_name, metrics in dataset_results.items():\n",
    "                all_results.append({\n",
    "                    \"Dataset\": dataset_name,\n",
    "                    \"Model\": model_name,\n",
    "                    \"Type\": metrics.get(\"model_type\", \"Unknown\"),\n",
    "                    \"Dimension\": metrics.get(\"dimension\", 0),\n",
    "                    \"Method\": metrics.get(\"similarity_method\", \"N/A\"),\n",
    "                    \"Pearson\": metrics.get(\"pearson\", np.nan),\n",
    "                    \"Spearman\": metrics.get(\"spearman\", np.nan),\n",
    "                    \"Coverage\": metrics.get(\"coverage\", 0),\n",
    "                    \"N_Pairs\": metrics.get(\"n_pairs\", 0)\n",
    "                })\n",
    "        \n",
    "        results_df = pd.DataFrame(all_results)\n",
    "        \n",
    "        # Display detailed results by dataset\n",
    "        for dataset in results_df['Dataset'].unique():\n",
    "            dataset_df = results_df[results_df['Dataset'] == dataset]\n",
    "            print(f\"\\n{dataset}:\")\n",
    "            print(\"-\" * 110)\n",
    "            print(f\"{'Model':<15} {'Type':<8} {'Dim':>4} {'Method':<8} {'Pearson':>8} {'Spearman':>8} {'Coverage':>10} {'N_Pairs':>8}\")\n",
    "            print(\"-\" * 120)\n",
    "            \n",
    "            dataset_df = dataset_df.sort_values(by=['Type', 'Dimension'])\n",
    "            \n",
    "            for _, row in dataset_df.iterrows():\n",
    "                pearson_str = f\"{row['Pearson']:.4f}\" if not pd.isna(row['Pearson']) else \"N/A\"\n",
    "                spearman_str = f\"{row['Spearman']:.4f}\" if not pd.isna(row['Spearman']) else \"N/A\"\n",
    "                coverage_str = f\"{row['Coverage']:.2%}\"\n",
    "                method_str = row.get('Method', 'N/A')\n",
    "                print(f\"{row['Model']:<15} {row['Type']:<8} {row['Dimension']:>4} {method_str:<8} {pearson_str:>8} {spearman_str:>8} {coverage_str:>10} {row['N_Pairs']:>8}\")\n",
    "        \n",
    "        # Display summary statistics\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(\"SUMMARY STATISTICS\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        summary = results_df.groupby(['Type', 'Dimension']).agg({\n",
    "            'Pearson': ['mean', 'std', 'count'],\n",
    "            'Spearman': ['mean', 'std'],\n",
    "            'Coverage': 'mean'\n",
    "        }).round(4)\n",
    "        \n",
    "        print(summary)\n",
    "        \n",
    "        return results_df\n",
    "    \n",
    "    def save_results(self, filepath=\"cpae_evaluation_results.csv\"):\n",
    "        \"\"\"Save results to CSV\"\"\"\n",
    "        if not self.results:\n",
    "            logger.info(\"No results to save!\")\n",
    "            return None\n",
    "        \n",
    "        all_results = []\n",
    "        for dataset_name, dataset_results in self.results.items():\n",
    "            for model_name, metrics in dataset_results.items():\n",
    "                all_results.append({\n",
    "                    \"Dataset\": dataset_name,\n",
    "                    \"Model\": model_name,\n",
    "                    \"Model_Type\": metrics.get(\"model_type\", \"Unknown\"),\n",
    "                    \"Dimension\": metrics.get(\"dimension\", 0),\n",
    "                    \"Similarity_Method\": metrics.get(\"similarity_method\", \"N/A\"),\n",
    "                    \"Pearson_Correlation\": metrics.get(\"pearson\", np.nan),\n",
    "                    \"Spearman_Correlation\": metrics.get(\"spearman\", np.nan),\n",
    "                    \"Coverage\": metrics.get(\"coverage\", 0),\n",
    "                    \"Valid_Pairs\": metrics.get(\"n_pairs\", 0)\n",
    "                })\n",
    "        \n",
    "        results_df = pd.DataFrame(all_results)\n",
    "        \n",
    "        os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "        results_df.to_csv(filepath, index=False)\n",
    "        logger.info(f\"Detailed results saved to: {filepath}\")\n",
    "        \n",
    "        # Save summary statistics\n",
    "        summary = results_df.groupby(['Model_Type', 'Dimension']).agg({\n",
    "            'Pearson_Correlation': ['mean', 'std', 'count'],\n",
    "            'Spearman_Correlation': ['mean', 'std'],\n",
    "            'Coverage': 'mean'\n",
    "        }).round(4)\n",
    "        \n",
    "        summary_file = \"cpae_evaluation_summary.csv\"\n",
    "        summary.to_csv(summary_file)\n",
    "        logger.info(f\"Summary statistics saved to: {summary_file}\")\n",
    "        \n",
    "        return results_df\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function: run complete evaluation process\"\"\"\n",
    "    # Check dependencies\n",
    "    missing_deps = []\n",
    "    required = [\"torch\", \"scipy\", \"sklearn\", \"pandas\", \"numpy\", \"nltk\"]\n",
    "    for dep in required:\n",
    "        try:\n",
    "            __import__(dep)\n",
    "        except ImportError:\n",
    "            missing_deps.append(dep)\n",
    "    \n",
    "    if missing_deps:\n",
    "        print(f\"Missing dependencies: {missing_deps}\")\n",
    "        print(\"Install with: pip install \" + \" \".join(missing_deps))\n",
    "        return None, None\n",
    "    \n",
    "    # Set project root directory\n",
    "    project_dir = \"your_project_directory\"\n",
    "\n",
    "    # Initialize evaluator\n",
    "    evaluator = CPAEHyperbolicEvaluator(project_dir)\n",
    "    \n",
    "    # Set paths\n",
    "    model_dir = os.path.join(project_dir, \"path_to_your_model_directory\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
